
# memo.md

## 目的

SVM をまずは使って動かしてみる

## 参照

Kindle
データサイエンティスト養成読本 特集4 第4章

kaggle, Cat Datasets, 2GBある。。
https://www.kaggle.com/crawford/cat-dataset

NMSの図形
https://docs.google.com/presentation/d/1FYgxdAeDVmo7wtlfCoXHYwF_iqbsmsZczl9USDnf814/edit?usp=sharing

## やること

正例画像の準備
負例画像の準備
データ下処理
モデル作成
正誤判定テスト

## 正例画像の準備

自宅でやる
2GB あるので、、

## 負例画像の準備

猫の写ってない画像 100 枚をダウンロードする
あー、タイヤデータ使おう

## データ下処理, 特徴量抽出

## モデル作成

## テスト用データ作成

## 正誤判定テスト

## 検出処理

モデル作成時の画像サイズと検出時の検出窓サイズを一致させる
検出窓内部の特徴量とターゲット画像の特徴量を比較しているから

モデル作成時のセルサイズと検出時のターゲット画像の特徴量のセルサイズを一致させる
セルサイズがずれると、ヒストグラムの値が変わるから

## NMS処理

## 精度上昇させる

画像認識では下記の順番で認識精度に影響する
訓練データの質と量
特徴量
機械学習手法

訓練データの質と量
正例画像と負例画像を増やす
アマゾンメカニカルタークのようなソーシャルサービスを使う
負例については単純に数を増やすより誤検出された部分を切り出して訓練データに加えると効果的
精霊の数が少ない場合はデータオーギュメンテーション、拡大・縮小・回転・コントラスト調整・反転して水増しする

## 管理しなければならないデータ

元データ
./DATA/CAT/
./DATA/TIRE/

正例画像
./DATA/POSITIVES/

負例画像
./DATA/NEGATIVES/

訓練データ
./get_feature.result

作成モデル
./make_model.result

画像検出テスト結果
目検結果
NGだった矩形と画像情報

## やりたい事

検出画像を生成
目検用HTMLを生成
目検を実施
誤検知の画像と矩形データから負例画像を作成

これは、実テストでためそうかなぁ。。
それとも、実案件でやるべきか。。

そもそも矩形が小さいきがする
検出時に拡大はしているけど縮小を取り入れてどうなるかを見てみたい
スケールファクターを 0.5、閾値を 6 近くにあげても誤検出していたのでトレインデータだと思う
ロジックは間違っていないと思う
負例データがタイヤだもうんなぁ。。

## 検出画像を生成

画像が一万枚ある
一万枚作るのは気が滅入るので正例データ作った時と同じ方法でピックアップしてみる

display_results.py を保存にして、for で回せば作れそう
時間がかかるなぁ。。

io.imsave('%s/%d.png' % (output_dir, i), face)

あー、コードの検索正が悪すぎる。。効率わるい！！
GitHub 検索できるようにしたい
フレクトアカウント作ろう
やめましたー、作られてない。。

なんか、アプローチが違う気がする
アノテーションファイルを作成する方が無駄なファイルを生成しなくてすむので処理が早そう

## 目検用HTMLを生成

matplot でもうちょっとらくできないかなぁ。
わざわざ、画像生成するのではなく
描画した画像に入力可能なテキストエリアを準備して、そこに、成功可否をいれるとか
でも画像一万枚みるとかやりたくないよね。。。
10枚見て、ダメなら切り替えた方が良いと思う
検出精度が測れないという、問題が。。

## 目検を実施

目検はアプローチが間違っている
画像とひもづくアノテーションデータがあれば誤検知を判断できる

## 誤検知判断を作成

何を誤検知とするかの定義が必要
POSITIVES の画像データと一致した場合
POSITIVES の画像生成ロジックが参考になると覆う
Accuracy = (正しく検出した座標数) / (誤検出した座標数)

クロップ処理する前の画像名と座標と幅と高さと一致すればOK にしよう
近似すればだと、閾値とかを考えなくちゃいけない
あー、nms の考え方が応用できる
8割面積が重なれば、OK とかできそう
それで。。

誤検知判断ロジックの作成
クロップ処理から猫顔座標を取得
精霊画像の数と猫顔で検出した数で差分がでとる。。
NMS処理から検出座標と猫顔座標の面積の重なり度で 9 割重なっていたら正解と判断する

## 誤検知の画像と矩形データから負例画像を作成

crop_faces.py を流用
画像パスと座標を渡し、クロップし、リサイズして、ファイル保存

## 使いした負例画像からモデルを作成、テスト、結果表示までを自動化する

初回手順

教師データの準備
crop_faces.py
crop_negatives.py

特徴量抽出
get_feature.py
get_histogram.py

モデル構築
make_model.py

モデル精度測定
select_test_data.sh
get_accuracy.py

検出処理
get_detections.py
apply_nms.py

検出精度測定
check_detection.py

2周目以降の手順

教師データの準備
create_new_negatives.py

特徴量抽出
get_feature.py
データ管理方法で悩む
追加されたデータを同一ディレクトリで管理するのか
複数ディレクトリで管理するのか
繰り返し反復するのでデータ量は増える
再現性がある
ディレクトリ毎に分かれている方がわかりやすいかも
ヒストグラム機能が二つに分かれている、修正が必要
get_feature.py のヒストグラムはldp を渡している
get_histogram.py のヒストグラムは画像をわたして、特徴量、ヒストグラムを同時に計算している
動作がちがうけど、まぁいいか。動くし
```
pickle.dump((X, y), open("./get_feature.result", 'wb'))
OSError: [Errno 22] Invalid argument
```

モデル構築
make_model.py

モデル精度測定
select_test_data.sh
get_accuracy.py

検出処理
get_detections.py
apply_nms.py
get_histogram.py
view_detections.py

検出精度測定
check_detection.py
create_new_negatives.py

EOF
